{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41d6e73-aaa8-4f83-b62a-cd2815e9f666",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "Before we get into an example of model deployment, we should cover a few Python techniques which will be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7afcc9-1750-4559-bb65-63f0341c5158",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Serialization\n",
    "\n",
    "Sometimes we want to save Python objects in the same way we save data or text files. To do this, we use a process called **[serialization](https://realpython.com/python-serialize-data/#get-an-overview-of-data-serialization)**. In short, we save only the necessary aspects of an object inside a file so that when it is loaded, the rest of the object can be recreated exactly as it was when it was saved. The packages that you import into a Python session can be used in this recreation, removing the need to save \"package-based\" content (e.g., the `.mean()` or `.groupby()` methods of a `pd.DataFrame` don't need to be stored in its pickle file).\n",
    "\n",
    "[There are many ways to serialize objects in Python](https://realpython.com/python-pickle-module/#serialization-in-python), but one of the most common and efficient ways is to [serialize with the pickle module](https://www.datacamp.com/tutorial/pickle-python-tutorial#serializing-python-data-structures-with-pickle-lists).\n",
    "\n",
    "To use pickle, we save *bytes* objects, and then load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc50566e-94e1-4994-b12a-c243510af8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f2fc5c-3158-4726-81f9-eb7773776a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stuff... \n",
    "my_object = ['this', 'is', 'an', 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242f8679-5807-42e2-9167-6656ac757a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice this Writes a Bytes object \"wb\"\n",
    "with open(\"./my_object.pickle\", 'wb') as f:\n",
    "    pickle.dump(my_object, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da915288-c28a-400b-9124-bf3743d1d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice this Reads a Bytes object \"rb\"\n",
    "with open(\"./my_object.pickle\", 'rb') as f:\n",
    "    my_object = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01df3808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'an', 'object']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f41f2-21df-4de0-94b6-0dd9d5f6173f",
   "metadata": {},
   "source": [
    "## Decorators\n",
    "\n",
    "Streamlit uses **[decorator functions](https://pythonbasics.org/decorators/)** to cache objects. In short, a decorator function \"wraps\" some other function, so that every time the *wrapped* function is used, the wrapp*er* is instantiated first. For more information on these, I recommend the first two main sections of the [RealPython article](https://realpython.com/primer-on-python-decorators) by Geir Arne Hjelle.\n",
    "\n",
    "For a **simple example**, the following code is adapted from the above article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f33448-e75a-442b-9a69-a0695b3c7caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intro_outro(func):\n",
    "    # we need to make a function to return a function ...\n",
    "    def wrapper():\n",
    "        print(\"This is an introduction.\")\n",
    "        func()\n",
    "        print(\"Thank you for your time!\")\n",
    "\n",
    "    # return the \"wrapped\" version of the function\n",
    "    return wrapper\n",
    "\n",
    "def say_whee():\n",
    "    print(\"Whee!\")\n",
    "\n",
    "# wrapped version of the function\n",
    "@intro_outro\n",
    "def wrap_say_whee():\n",
    "    print(\"Whee!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b42827d-8a3a-4980-bdba-2c5a0f331371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whee!\n"
     ]
    }
   ],
   "source": [
    "say_whee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6e5ca3-fac8-4d49-b9a3-295ee68347f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an introduction.\n",
      "Whee!\n",
      "Thank you for your time!\n"
     ]
    }
   ],
   "source": [
    "wrap_say_whee()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405aca4-b938-4a76-8cd6-3e2247bb10ce",
   "metadata": {},
   "source": [
    "As a **more involved example**, we can pass arguments and keyword arguments to the wrapped function within the decorator wrapper using `*args` and `**kwargs`. Recall, that these uses of `*` notation will *unpack* lists (of arguments) and dictionaries (of keyword arguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f966f62e-fd18-41f0-af42-05be79a08b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_twice(func):\n",
    "    def wrapper_do_twice(*args, **kwargs):\n",
    "        func(*args, **kwargs)\n",
    "        func(*args, **kwargs)\n",
    "    return wrapper_do_twice\n",
    "\n",
    "@do_twice\n",
    "def say_something(statement=\"this is what I want to say.\"):\n",
    "    print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bd1eab-8737-4bfe-9a35-c8e794f7b54f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is also what I want to say.\n",
      "this is also what I want to say.\n"
     ]
    }
   ],
   "source": [
    "say_something('this is also what I want to say.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549927fb-823a-40f5-966a-c9408a79aea3",
   "metadata": {},
   "source": [
    "(Optional) For an even more **complex example**, take a look at the ways you can [define a decorator with arguments](https://realpython.com/primer-on-python-decorators/#defining-decorators-with-arguments), or even [define a decorator with *optional* arguments](https://realpython.com/primer-on-python-decorators/#creating-decorators-with-optional-arguments)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2233c8",
   "metadata": {},
   "source": [
    "## Remote Storage\n",
    "\n",
    "When running applications on the cloud, you should **avoid saving project data to GitHub.** Similarly, you should want to avoid saving anything else that might be large (e.g., large models, etc.). One immediate reason for this is that GitHub is not built for storing lots of data (or copies of that data for each commit!), and large files can make GitHub operations unwieldy (e.g., note that pushing=uploading and pulling=downloading). Further, data and models usually require some level of security, and public GitHub models are available to anyone. Thus, your data (or objects) should be stored on the cloud using a cloud storage service.\n",
    "\n",
    "The most common cloud services are Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure. If your organization isn't using in-house, proprietary servers, it is almost surely using one of these three options. However, aside from the fact that these tools are not free, they are also out of the scope of this course. Instead, we use Google Drive, as described in the Simple Streamlit example linked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cbb04-80b2-4f38-9baa-365317c280f6",
   "metadata": {},
   "source": [
    "# Simple Streamlit\n",
    "\n",
    "As a supplement to this lab, we have a [simple Streamlit web app](https://github.com/leontoddjohnson/simple_streamlit) that demonstrates how to deploy a model that uses data stored on Backblaze:\n",
    "\n",
    "1. **[Fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo?tool=webui)** the [simple_streamlit](https://github.com/leontoddjohnson/simple_streamlit) repository on GitHub.\n",
    "2. Then, **[clone](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository?tool=desktop)** that fork (from your GitHub account) onto your local machine using GitHub Desktop.\n",
    "3. Follow the steps on the README.md file, and use that fork as your own template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee085d37",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "Test your understanding of this week's content with the following explorations.\n",
    "\n",
    "*Note: unless otherwise noted, **explorations are completely optional and will not be reviewed.***\n",
    "\n",
    "## Exploration 1\n",
    "\n",
    "Write a `@timer` decorator that will print the time it takes for a function to run. You can use the `time` Python module to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f963eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
